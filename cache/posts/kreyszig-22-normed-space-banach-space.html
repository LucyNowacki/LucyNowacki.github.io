<p><strong>Problem 1.</strong> Show that the norm <span class="math">\(\|x\|\)</span> of x is the distance from x to O.</p>
<p><strong>Definition:</strong></p>
<p>A <em>norm</em> on a (real or complex) vector space <span class="math">\(X\)</span> is a
real-valued function on <span class="math">\(X\)</span> whose value at an <span class="math">\(x \in X\)</span> is denoted by
<span class="math">\(\|x\|\)</span> (read &quot;norm of x&quot;) and which has the properties</p>
<ul class="simple">
<li><p><span class="math">\(\|x\| \geq 0\)</span> (Non-negativity)</p></li>
<li><p><span class="math">\(\|x\| = 0 \iff x = 0\)</span> (Definiteness)</p></li>
<li><p><span class="math">\(\|a x\| = |a| \|x\|\)</span> (Homogeneity)</p></li>
<li><p><span class="math">\(\|x + y\| \leq \|x\| + \|y\|\)</span> (Triangle Inequality);</p></li>
</ul>
<p>here <span class="math">\(x\)</span> and <span class="math">\(y\)</span> are arbitrary vectors in <span class="math">\(X\)</span> and <span class="math">\(a\)</span> is any scalar.</p>
<p><strong>Solution:</strong></p>
<p>The norm <span class="math">\(\|x\|\)</span> of a vector <span class="math">\(x\)</span> in a vector space is a generalization of the notion of &quot;length&quot; of a vector.
It measures the size of vectors and is consistent with our geometric intuition.</p>
<p>In a normed vector space, the distance <span class="math">\(d\)</span> between two vectors <span class="math">\(x\)</span> and <span class="math">\(y\)</span> is defined as:</p>
<div class="math">
\begin{equation*}
d(x, y) = \|x - y\|
\end{equation*}
</div>
<p>The distance from any vector <span class="math">\(x\)</span> to the origin <span class="math">\(O\)</span> (the zero vector <span class="math">\(0\)</span>) is then:</p>
<div class="math">
\begin{equation*}
d(x, O) = \|x - 0\|
\end{equation*}
</div>
<p>Since subtracting the zero vector does not change the vector <span class="math">\(x\)</span>, we have:</p>
<div class="math">
\begin{equation*}
d(x, O) = \|x\|
\end{equation*}
</div>
<p>Thus, the norm <span class="math">\(\|x\|\)</span> is the distance from the vector <span class="math">\(x\)</span> to the origin <span class="math">\(O\)</span> in the vector space <span class="math">\(X\)</span>.
This relationship holds in any normed vector space, whether it be a space of real numbers, complex numbers, or more abstract objects.</p>
<hr class="docutils" />
<p><strong>Problem 2.</strong> Verify that the usual length of a vector in the plane or in three-dimensional space has the properties (N1) to (N4) of a norm.</p>
<p><strong>Solution:</strong></p>
<p><strong>In the Plane</strong> (<span class="math">\(\mathbb{R}^2\)</span>)</p>
<p>For a vector <span class="math">\(x = (x_1, x_2)\)</span> in <span class="math">\(\mathbb{R}^2\)</span>, the usual length (Euclidean norm) is defined as:</p>
<div class="math">
\begin{equation*}
\|x\| = \sqrt{x_1^2 + x_2^2}
\end{equation*}
</div>
<p><strong>Property (N1): Non-negativity</strong></p>
<div class="math">
\begin{equation*}
\|x\| = \sqrt{x_1^2 + x_2^2} \geq 0
\end{equation*}
</div>
<p>The square of any real number is non-negative, and the square root of a non-negative number is also non-negative.</p>
<p><strong>Property (N2): Definiteness</strong></p>
<div class="math">
\begin{equation*}
\|x\| = 0 \iff x_1^2 + x_2^2 = 0 \iff x_1 = 0 \text{ and } x_2 = 0 \iff x = (0, 0)
\end{equation*}
</div>
<p>The norm is zero if and only if both components of the vector are zero.</p>
<p><strong>Property (N3): Homogeneity</strong></p>
<p>For any scalar <span class="math">\(a\)</span> and vector <span class="math">\(x = (x_1, x_2)\)</span>,</p>
<div class="math">
\begin{equation*}
\|a \cdot x\| = \| (a x_1, a x_2) \| = \sqrt{(a x_1)^2 + (a x_2)^2} = |a| \cdot \sqrt{x_1^2 + x_2^2} = |a| \cdot \|x\|
\end{equation*}
</div>
<p>The norm of a scaled vector is the absolute value of the scalar times the norm of the vector.</p>
<p><strong>Property (N4): Triangle Inequality</strong></p>
<p>For any vectors <span class="math">\(x = (x_1, x_2)\)</span> and <span class="math">\(y = (y_1, y_2)\)</span>, let's consider the norm of their sum:</p>
<div class="math">
\begin{equation*}
\|x + y\| = \| (x_1 + y_1, x_2 + y_2) \| = \sqrt{(x_1 + y_1)^2 + (x_2 + y_2)^2}
\end{equation*}
</div>
<p>To prove the triangle inequality, we expand the square of the norm of <span class="math">\(x + y\)</span>:</p>
<div class="math">
\begin{equation*}
\|x + y\|^2 = x_1^2 + 2x_1y_1 + y_1^2 + x_2^2 + 2x_2y_2 + y_2^2
\end{equation*}
</div>
<p>We can rewrite this as:</p>
<div class="math">
\begin{equation*}
\|x + y\|^2 = \|x\|^2 + 2\langle x, y \rangle + \|y\|^2
\end{equation*}
</div>
<p>By the Cauchy-Schwarz inequality, we know:</p>
<div class="math">
\begin{equation*}
|\langle x, y \rangle| \leq \|x\| \cdot \|y\|
\end{equation*}
</div>
<p>So we have:</p>
<div class="math">
\begin{equation*}
\|x + y\|^2 \leq \|x\|^2 + 2\|x\| \cdot \|y\| + \|y\|^2 = (\|x\| + \|y\|)^2
\end{equation*}
</div>
<p>Taking the square root of both sides (and remembering that the square root function is increasing), we get:</p>
<div class="math">
\begin{equation*}
\|x + y\| \leq \|x\| + \|y\|
\end{equation*}
</div>
<p>This completes the proof of the triangle inequality for vectors in <span class="math">\(\mathbb{R}^2\)</span>.</p>
<p><strong>In Three-Dimensional Space (:math:`mathbb{R}^3`)</strong></p>
<p>The verification of properties (N1) to (N4) in three-dimensional space follows similarly to that in the plane, with the addition of the third component for each vector. The proof of the triangle inequality in <span class="math">\(\mathbb{R}^3\)</span> follows the same steps as above.</p>
<p><strong>Concavity of the Square Root Function</strong></p>
<p>The function <span class="math">\(f(t) = \sqrt{t}\)</span> is concave on <span class="math">\([0, \infty)\)</span> because its second derivative is negative:</p>
<div class="math">
\begin{equation*}
f''(t) = -\frac{1}{4t^{3/2}} &lt; 0 \text{ for all } t &gt; 0
\end{equation*}
</div>
<p>The concavity of the square root function ensures that the function applied to a sum is less than or equal to the sum of the functions applied to each term separately, which is consistent with the triangle inequality as we've just proven.</p>
<p>The above reasoning solidifies that the Euclidean norm satisfies the triangle inequality, completing the verification that it indeed constitutes a norm in both <span class="math">\(\mathbb{R}^2\)</span> and <span class="math">\(\mathbb{R}^3\)</span>.</p>
<p><strong>Detailed Transition</strong></p>
<p>Consider two vectors <span class="math">\(x\)</span> and <span class="math">\(y\)</span> in <span class="math">\(\mathbb{R}^n\)</span>. The squared norm of their sum is:</p>
<div class="math">
\begin{equation*}
\|x + y\|^2 = \langle x + y, x + y \rangle
\end{equation*}
</div>
<p>Expanding the inner product:</p>
<div class="math">
\begin{equation*}
\|x + y\|^2 = \langle x, x \rangle + 2\langle x, y \rangle + \langle y, y \rangle
\end{equation*}
</div>
<p>The inner product of a vector with itself is the square of its norm:</p>
<div class="math">
\begin{equation*}
\|x + y\|^2 = \|x\|^2 + 2\langle x, y \rangle + \|y\|^2
\end{equation*}
</div>
<p>By the Cauchy-Schwarz inequality:</p>
<div class="math">
\begin{equation*}
|\langle x, y \rangle| \leq \|x\| \cdot \|y\|
\end{equation*}
</div>
<p>This implies:</p>
<div class="math">
\begin{equation*}
2|\langle x, y \rangle| \leq 2\|x\| \cdot \|y\|
\end{equation*}
</div>
<p>Since the norms are non-negative, and the inner product can be negative, we use the absolute value:</p>
<div class="math">
\begin{equation*}
2\langle x, y \rangle \leq 2\|x\| \cdot \|y\|
\end{equation*}
</div>
<p>Substituting back into our expanded norm equation:</p>
<div class="math">
\begin{equation*}
\|x + y\|^2 \leq \|x\|^2 + 2\|x\| \cdot \|y\| + \|y\|^2
\end{equation*}
</div>
<p>The right-hand side is the square of <span class="math">\(\|x\| + \|y\|\)</span>:</p>
<div class="math">
\begin{equation*}
\|x + y\|^2 \leq (\|x\| + \|y\|)^2
\end{equation*}
</div>
<p>Taking the square root of both sides, since the square root function is monotonically increasing:</p>
<div class="math">
\begin{equation*}
\|x + y\| \leq \|x\| + \|y\|
\end{equation*}
</div>
<p>This is the triangle inequality for norms, demonstrating that the Euclidean norm satisfies property (N4).</p>
<hr class="docutils" />
<p><strong>Problem 4.</strong> Show that we may replace (N2) by <span class="math">\(\|x\| = 0 \iff x = 0\)</span> without altering the concept of a norm. Show that non-negativity of a norm also follows from (N3) and (N4).</p>
<p><strong>Solution:</strong></p>
<p><strong>Part 1: Replacing (N2)</strong></p>
<p>The definiteness condition states that <span class="math">\(\|x\| = 0 \iff x = 0\)</span>. This condition is crucial because it ensures that the only vector with a norm of zero is the zero vector itself.</p>
<p><strong>Part 2: Non-negativity from (N3) and (N4)</strong></p>
<p><strong>Property (N3)</strong> states that <span class="math">\(\|a x\| = |a| \|x\|\)</span> for any scalar <span class="math">\(a\)</span> and any vector <span class="math">\(x\)</span>. This property is known as absolute homogeneity or scalability.</p>
<p><strong>Property (N4)</strong> is the triangle inequality, which states that <span class="math">\(\|x + y\| \leq \|x\| + \|y\|\)</span> for any vectors <span class="math">\(x\)</span> and <span class="math">\(y\)</span>.</p>
<p>To show that non-negativity follows from (N3) and (N4), consider the following:</p>
<p>For any vector <span class="math">\(x\)</span> in the vector space, by property (N3), we have:</p>
<div class="math">
\begin{equation*}
\|0 \cdot x\| = |0| \|x\| = 0
\end{equation*}
</div>
<p>Here we used the fact that multiplying any vector by zero yields the zero vector, and the absolute value of zero is zero. This gives us the result that <span class="math">\(\|0\| = 0\)</span>.</p>
<p>Now, using the triangle inequality (N4), for any vector <span class="math">\(x\)</span>:</p>
<div class="math">
\begin{equation*}
\|x\| = \|x + 0\| \leq \|x\| + \|0\|
\end{equation*}
</div>
<p>Since we've established that <span class="math">\(\|0\| = 0\)</span>, this simplifies to:</p>
<div class="math">
\begin{equation*}
\|x\| \leq \|x\| + 0
\end{equation*}
</div>
<p>Thus, <span class="math">\(\|x\| \leq \|x\|\)</span>, which is true by the reflexivity of the inequality. This shows that <span class="math">\(\|x\|\)</span> must be non-negative since it cannot be less than itself.</p>
<p>Together, these parts demonstrate that the property (N2) can be replaced by the definiteness condition without changing the concept of a norm, and that non-negativity can be derived from (N3) and (N4), confirming that these properties are sufficient to define a norm.</p>
<hr class="docutils" />
<p><strong>Problem 5.</strong> Show that the Euclidean norm with components <span class="math">\(x_i\)</span> replaced by <span class="math">\(\xi_i\)</span> and scalar <span class="math">\(a\)</span> replaced by <span class="math">\(\alpha\)</span> defines a norm on the vector space <span class="math">\(\mathbb{R}^n\)</span>.</p>
<p><strong>Solution:</strong></p>
<p>To demonstrate that the Euclidean norm defines a norm on <span class="math">\(\mathbb{R}^n\)</span> with the components <span class="math">\(x_i\)</span> replaced by <span class="math">\(\xi_i\)</span> and the scalar <span class="math">\(a\)</span> replaced by <span class="math">\(\alpha\)</span>, we must verify that it satisfies the following properties:</p>
<ol class="arabic">
<li><p><strong>Non-negativity:</strong> For any vector <span class="math">\(x\)</span>, since each component <span class="math">\(\xi_i\)</span> is squared, the sum is non-negative. Therefore, <span class="math">\(\|x\| \geq 0\)</span>.</p></li>
<li><p><strong>Definiteness:</strong> The norm <span class="math">\(\|x\|\)</span> equals zero if and only if every <span class="math">\(\xi_i\)</span> is zero, which implies that <span class="math">\(x\)</span> is the zero vector.</p></li>
<li><p><strong>Homogeneity (or scalability):</strong> For any scalar <span class="math">\(\alpha\)</span> and vector <span class="math">\(x\)</span>, the norm of the scaled vector is given by:</p>
<div class="math">
\begin{equation*}
\|\alpha x\| = \sqrt{\sum_{i=1}^{n} (\alpha \xi_i)^2} = |\alpha| \sqrt{\sum_{i=1}^{n} \xi_i^2} = |\alpha| \|x\|
\end{equation*}
</div>
</li>
<li><p><strong>Triangle Inequality:</strong> For vectors <span class="math">\(x = (\xi_1, \xi_2, \ldots, \xi_n)\)</span> and <span class="math">\(y = (\eta_1, \eta_2, \ldots, \eta_n)\)</span>, we need to show that <span class="math">\(\|x + y\| \leq \|x\| + \|y\|\)</span>.</p>
<p>Starting with the left side of the inequality:</p>
<div class="math">
\begin{equation*}
\|x + y\|^2 = \sum_{i=1}^{n} (\xi_i + \eta_i)^2 = \sum_{i=1}^{n} (\xi_i^2 + 2\xi_i\eta_i + \eta_i^2)
\end{equation*}
</div>
<p>Applying the Cauchy-Schwarz inequality:</p>
<div class="math">
\begin{equation*}
\left| \sum_{i=1}^{n} \xi_i\eta_i \right| \leq \sqrt{\sum_{i=1}^{n} \xi_i^2} \cdot \sqrt{\sum_{i=1}^{n} \eta_i^2}
\end{equation*}
</div>
<p>We then have:</p>
<div class="math">
\begin{equation*}
2\sum_{i=1}^{n} \xi_i\eta_i \leq 2\sqrt{\sum_{i=1}^{n} \xi_i^2} \cdot \sqrt{\sum_{i=1}^{n} \eta_i^2}
\end{equation*}
</div>
<p>Substituting this back into the squared norm of <span class="math">\(x + y\)</span>, we get:</p>
<div class="math">
\begin{equation*}
\|x + y\|^2 \leq \sum_{i=1}^{n} \xi_i^2 + 2\sqrt{\sum_{i=1}^{n} \xi_i^2} \cdot \sqrt{\sum_{i=1}^{n} \eta_i^2} + \sum_{i=1}^{n} \eta_i^2
\end{equation*}
</div>
<p>Which simplifies to:</p>
<div class="math">
\begin{equation*}
\|x + y\|^2 \leq \left( \sqrt{\sum_{i=1}^{n} \xi_i^2} + \sqrt{\sum_{i=1}^{n} \eta_i^2} \right)^2
\end{equation*}
</div>
<p>Taking the square root of both sides:</p>
<div class="math">
\begin{equation*}
\|x + y\| \leq \sqrt{\sum_{i=1}^{n} \xi_i^2} + \sqrt{\sum_{i=1}^{n} \eta_i^2}
\end{equation*}
</div>
<p>Thus, we have proven the triangle inequality:</p>
<div class="math">
\begin{equation*}
\|x + y\| \leq \|x\| + \|y\|
\end{equation*}
</div>
</li>
</ol>
<p>By confirming these properties, we have shown that the Euclidean norm with substitutions <span class="math">\(\xi_i\)</span> for <span class="math">\(x_i\)</span> and <span class="math">\(\alpha\)</span> for <span class="math">\(a\)</span> indeed defines a norm on the vector space <span class="math">\(\mathbb{R}^n\)</span>.</p>
<hr class="docutils" />
<p><strong>Problem 6.</strong> Let <span class="math">\(X\)</span> be the vector space of all ordered pairs <span class="math">\(x = (\xi_1, \xi_2)\)</span>, <span class="math">\(y = (\eta_1, \eta_2)\)</span>, ... of real numbers. We are to show that norms on <span class="math">\(X\)</span> are defined by:</p>
<div class="math">
\begin{equation*}
\|x\|_1 = |\xi_1| + |\xi_2|
\end{equation*}
</div>
<div class="math">
\begin{equation*}
\|x\|_2 = (\xi_1^2 + \xi_2^2)^{1/2}
\end{equation*}
</div>
<div class="math">
\begin{equation*}
\|x\|_{\infty} = \max\{|\xi_1|, |\xi_2|\}
\end{equation*}
</div>
<p><strong>Solution:</strong></p>
<ol class="arabic simple">
<li><p>For the <span class="math">\(L^1\)</span> norm:</p>
<ul class="simple">
<li><p>Non-negativity: Since absolute values are always non-negative, we have <span class="math">\(|\xi_1| + |\xi_2| \geq 0\)</span>.</p></li>
<li><p>Definiteness: <span class="math">\(\|x\|_1 = 0\)</span> if and only if <span class="math">\(|\xi_1| = 0\)</span> and <span class="math">\(|\xi_2| = 0\)</span>, which occurs if and only if <span class="math">\(\xi_1 = 0\)</span> and <span class="math">\(\xi_2 = 0\)</span>, hence <span class="math">\(x = 0\)</span>.</p></li>
<li><p>Scalar multiplication: For any scalar <span class="math">\(\alpha\)</span>, <span class="math">\(\|\alpha x\|_1 = |\alpha \xi_1| + |\alpha \xi_2| = |\alpha|(|\xi_1| + |\xi_2|) = |\alpha| \|x\|_1\)</span>.</p></li>
<li><p>Triangle inequality: For any vectors <span class="math">\(x = (\xi_1, \xi_2)\)</span> and <span class="math">\(y = (\eta_1, \eta_2)\)</span>, <span class="math">\(\|x + y\|_1 = |(\xi_1 + \eta_1)| + |(\xi_2 + \eta_2)| \leq (|\xi_1| + |\eta_1|) + (|\xi_2| + |\eta_2|) = \|x\|_1 + \|y\|_1\)</span>.</p></li>
</ul>
</li>
<li><p>For the <span class="math">\(L^2\)</span> norm:</p>
<ul class="simple">
<li><p>Non-negativity: The sum of squares is non-negative, and so is their square root, hence <span class="math">\(\|x\|_2 \geq 0\)</span>.</p></li>
<li><p>Definiteness: <span class="math">\(\|x\|_2 = 0\)</span> if and only if <span class="math">\(\xi_1^2 + \xi_2^2 = 0\)</span>, which occurs only when <span class="math">\(\xi_1 = 0\)</span> and <span class="math">\(\xi_2 = 0\)</span>, thus <span class="math">\(x = 0\)</span>.</p></li>
<li><p>Scalar multiplication: <span class="math">\(\|\alpha x\|_2 = ((\alpha \xi_1)^2 + (\alpha \xi_2)^2)^{1/2} = |\alpha| (\xi_1^2 + \xi_2^2)^{1/2} = |\alpha| \|x\|_2\)</span>.</p></li>
<li><p>Triangle inequality: This follows from the Minkowski inequality, which is a general result and holds for the <span class="math">\(L^2\)</span> norm.</p></li>
</ul>
</li>
<li><p>For the <span class="math">\(L^\infty\)</span> norm:</p>
<ul class="simple">
<li><p>Non-negativity: The maximum of absolute values is non-negative, so <span class="math">\(\|x\|_{\infty} \geq 0\)</span>.</p></li>
<li><p>Definiteness: <span class="math">\(\|x\|_{\infty} = 0\)</span> if and only if both <span class="math">\(|\xi_1| = 0\)</span> and <span class="math">\(|\xi_2| = 0\)</span>, which means <span class="math">\(x = 0\)</span>.</p></li>
<li><p>Scalar multiplication: For any scalar <span class="math">\(\alpha\)</span>, <span class="math">\(\|\alpha x\|_{\infty} = \max\{|\alpha \xi_1|, |\alpha \xi_2|\} = |\alpha| \max\{|\xi_1|, |\xi_2|\} = |\alpha| \|x\|_{\infty}\)</span>.</p></li>
<li><p>Triangle inequality: For any vectors <span class="math">\(x\)</span> and <span class="math">\(y\)</span>, <span class="math">\(\|x + y\|_{\infty} \leq \|x\|_{\infty} + \|y\|_{\infty}\)</span> because the maximum absolute value of the sum of components is less than or equal to the sum of the maximum absolute values.</p></li>
</ul>
</li>
</ol>
<p><strong>Triangle inequality</strong></p>
<p>For the <span class="math">\(L^2\)</span> norm, we want to prove the triangle inequality:</p>
<div class="math">
\begin{equation*}
\|x + y\|_2 \leq \|x\|_2 + \|y\|_2
\end{equation*}
</div>
<p>where <span class="math">\(x = (\xi_1, \xi_2)\)</span> and <span class="math">\(y = (\eta_1, \eta_2)\)</span>. We start by squaring both sides of the inequality:</p>
<div class="math">
\begin{equation*}
(\|x + y\|_2)^2 \leq (\|x\|_2 + \|y\|_2)^2
\end{equation*}
</div>
<p>Expanding the left-hand side, we have:</p>
<div class="math">
\begin{equation*}
(\xi_1 + \eta_1)^2 + (\xi_2 + \eta_2)^2
\end{equation*}
</div>
<p>And the right-hand side becomes:</p>
<div class="math">
\begin{equation*}
(\|x\|_2)^2 + 2\|x\|_2\|y\|_2 + (\|y\|_2)^2
\end{equation*}
</div>
<p>Simplifying the norms, we obtain:</p>
<div class="math">
\begin{equation*}
\xi_1^2 + 2\xi_1\eta_1 + \eta_1^2 + \xi_2^2 + 2\xi_2\eta_2 + \eta_2^2 \leq \xi_1^2 + \xi_2^2 + 2\sqrt{(\xi_1^2 + \xi_2^2)(\eta_1^2 + \eta_2^2)} + \eta_1^2 + \eta_2^2
\end{equation*}
</div>
<p>The inequality holds due to the Cauchy-Schwarz inequality, which asserts:</p>
<div class="math">
\begin{equation*}
(\sum a_i b_i)^2 \leq (\sum a_i^2)(\sum b_i^2)
\end{equation*}
</div>
<p>In our case, it implies:</p>
<div class="math">
\begin{equation*}
(2\xi_1\eta_1 + 2\xi_2\eta_2)^2 \leq (2\sqrt{(\xi_1^2 + \xi_2^2)(\eta_1^2 + \eta_2^2)})^2
\end{equation*}
</div>
<p>Since the inequality holds when squared, it also holds when we take the square root of both sides, which gives us the triangle inequality for the <span class="math">\(L^2\)</span> norm:</p>
<div class="math">
\begin{equation*}
\|x + y\|_2 \leq \|x\|_2 + \|y\|_2
\end{equation*}
</div>
<hr class="docutils" />
<p><strong>Problem 7.</strong> Prove that the vector space of all continuous real-valued functions on <span class="math">\([a, b]\)</span> forms a normed space <span class="math">\(X\)</span> with norm defined by</p>
<div class="math">
\begin{equation*}
\|x\| = \left( \int_a^b x(t)^2 \, dt \right)^{1/2}
\end{equation*}
</div>
<p>satisfies the properties (N1) to (N4).</p>
<p><strong>Solution:</strong></p>
<p>To prove that the given norm satisfies the properties (N1) to (N4), we consider two functions <span class="math">\(x(t)\)</span> and <span class="math">\(y(t)\)</span> from the vector space, and a scalar <span class="math">\(\alpha\)</span>.</p>
<p>(N1) Non-negativity:
Since <span class="math">\(x(t)^2 \geq 0\)</span> for all <span class="math">\(t\)</span>, it follows that</p>
<div class="math">
\begin{equation*}
\|x\| = \left( \int_a^b x(t)^2 \, dt \right)^{1/2} \geq 0.
\end{equation*}
</div>
<p>(N2) Definiteness:
If <span class="math">\(\|x\| = 0\)</span>, then</p>
<div class="math">
\begin{equation*}
\int_a^b x(t)^2 \, dt = 0.
\end{equation*}
</div>
<p>Since <span class="math">\(x(t)^2 \geq 0\)</span>, this implies <span class="math">\(x(t)^2 = 0\)</span> almost everywhere, and hence <span class="math">\(x(t) = 0\)</span> almost everywhere.</p>
<p>(N3) Scalar multiplication:
We have</p>
<div class="math">
\begin{equation*}
\|\alpha x\| = \left( \int_a^b (\alpha x(t))^2 \, dt \right)^{1/2} = |\alpha| \left( \int_a^b x(t)^2 \, dt \right)^{1/2} = |\alpha| \|x\|.
\end{equation*}
</div>
<p>(N4) Triangle inequality:
The proof of the triangle inequality for this norm involves the Cauchy-Schwarz inequality for integrals. We start by expanding the square of the norm of the sum:</p>
<div class="math">
\begin{equation*}
\|x + y\|^2 = \int_a^b (x(t) + y(t))^2 \, dt.
\end{equation*}
</div>
<p>Expanding the integrand and applying the Cauchy-Schwarz inequality, we get:</p>
<div class="math">
\begin{equation*}
\int_a^b (x(t) + y(t))^2 \, dt = \int_a^b x(t)^2 \, dt + 2\int_a^b x(t)y(t) \, dt + \int_a^b y(t)^2 \, dt \leq \int_a^b x(t)^2 \, dt + 2\left(\int_a^b x(t)^2 \, dt\right)^{1/2} \left(\int_a^b y(t)^2 \, dt\right)^{1/2} + \int_a^b y(t)^2 \, dt.
\end{equation*}
</div>
<p>This implies:</p>
<div class="math">
\begin{equation*}
\|x + y\|^2 \leq \left( \left( \int_a^b x(t)^2 \, dt \right)^{1/2} + \left( \int_a^b y(t)^2 \, dt \right)^{1/2} \right)^2.
\end{equation*}
</div>
<p>Taking the square root of both sides, we obtain the triangle inequality:</p>
<div class="math">
\begin{equation*}
\|x + y\| \leq \|x\| + \|y\|.
\end{equation*}
</div>
<p>This completes the proof that the vector space of all continuous real-valued functions on <span class="math">\([a, b]\)</span> with the given norm is a normed space.</p>
<p><strong>The more detailes for triangle inequality are:</strong></p>
<div class="math">
\begin{equation*}
\|x+y\|^2 = \int_a^b (x(t) + y(t))^2 \, dt
\end{equation*}
</div>
<p>We expand the integrand:</p>
<div class="math">
\begin{equation*}
\int_a^b (x(t) + y(t))^2 \, dt = \int_a^b (x(t)^2 + 2x(t)y(t) + y(t)^2) \, dt
\end{equation*}
</div>
<p>We then split the integral:</p>
<div class="math">
\begin{equation*}
\int_a^b (x(t)^2 + 2x(t)y(t) + y(t)^2) \, dt = \int_a^b x(t)^2 \, dt + 2\int_a^b x(t)y(t) \, dt + \int_a^b y(t)^2 \, dt
\end{equation*}
</div>
<p>Using the Cauchy-Schwarz inequality for integrals to handle the cross-term:</p>
<div class="math">
\begin{equation*}
\left(\int_a^b x(t)y(t) \, dt\right)^2 \leq \left(\int_a^b x(t)^2 \, dt\right) \left(\int_a^b y(t)^2 \, dt\right)
\end{equation*}
</div>
<p>This implies that:</p>
<div class="math">
\begin{equation*}
2\int_a^b x(t)y(t) \, dt \leq 2\left(\int_a^b x(t)^2 \, dt\right)^{1/2} \left(\int_a^b y(t)^2 \, dt\right)^{1/2}
\end{equation*}
</div>
<p>Combine the results to get an upper bound for the integral of the sum:</p>
<div class="math">
\begin{equation*}
\|x+y\|^2 \leq \int_a^b x(t)^2 \, dt + 2\left(\int_a^b x(t)^2 \, dt\right)^{1/2} \left(\int_a^b y(t)^2 \, dt\right)^{1/2} + \int_a^b y(t)^2 \, dt
\end{equation*}
</div>
<p>Recognizing that the right-hand side is a perfect square:</p>
<div class="math">
\begin{equation*}
\|x+y\|^2 \leq \left( \left( \int_a^b x(t)^2 \, dt \right)^{1/2} + \left( \int_a^b y(t)^2 \, dt \right)^{1/2} \right)^2
\end{equation*}
</div>
<p>Since both sides are positive, we can take the square root:</p>
<div class="math">
\begin{equation*}
\|x+y\| \leq \left( \int_a^b x(t)^2 \, dt \right)^{1/2} + \left( \int_a^b y(t)^2 \, dt \right)^{1/2}
\end{equation*}
</div>
<p>Which simplifies to the triangle inequality for the <span class="math">\(L^2\)</span> norm:</p>
<div class="math">
\begin{equation*}
\|x+y\| \leq \|x\| + \|y\|
\end{equation*}
</div>
<p>This completes the proof for the triangle inequality of the <span class="math">\(L^2\)</span> norm in the vector space of continuous real-valued functions on <span class="math">\([a, b]\)</span>.</p>
<hr class="docutils" />
<p><strong>Problem 8.</strong> There are several norms of practical importance on the vector space ofordered n-tuples of numbers
- <span class="math">\(||x||_1 = |\xi _1| + |\xi _2| + \ldots + |\xi _n|\)</span>
- <span class="math">\(||x||_p = (|\xi _1|^p + |\xi _2|^p + \ldots + |\xi _n|^p)^{1/p}\)</span> for <span class="math">\(p \geq 1\)</span>
- <span class="math">\(||x||_\infty = \max\{|\xi _1|, |\xi _2|, \ldots, |\xi _n|\}\)</span></p>
<p><strong>Solution:</strong></p>
<p>To verify that each of these functions is a norm, we need to show they satisfy the four properties of norms:</p>
<ol class="arabic simple">
<li><p>Non-negativity: <span class="math">\(||x|| \geq 0\)</span> for all <span class="math">\(x \in X\)</span>.</p></li>
<li><p>Definiteness: <span class="math">\(||x|| = 0\)</span> if and only if <span class="math">\(x\)</span> is the zero vector.</p></li>
<li><p>Homogeneity (or scalability): <span class="math">\(||\alpha x|| = |\alpha| ||x||\)</span> for any scalar <span class="math">\(\alpha\)</span> and any <span class="math">\(x \in X\)</span>.</p></li>
<li><p>Triangle inequality: <span class="math">\(||x + y|| \leq ||x|| + ||y||\)</span> for all <span class="math">\(x, y \in X\)</span>.</p></li>
</ol>
<p>For the <span class="math">\(p\)</span>-norm, the first three properties are straightforward to verify. The triangle inequality for the <span class="math">\(p\)</span>-norm is established by Minkowski's inequality.</p>
<div class="math">
\begin{equation*}
\left(\sum_{i=1}^{n} |\xi _i + \eta _i|^p\right)^{1/p} \leq \left(\sum_{i=1}^{n} |\xi _i|^p\right)^{1/p} + \left(\sum_{i=1}^{n} |\eta _i|^p\right)^{1/p}
\end{equation*}
</div>
<p>This is the triangle inequality for the <span class="math">\(p\)</span>-norms. To prove Minkowski's inequality, we consider:</p>
<ul class="simple">
<li><p>For <span class="math">\(p=1\)</span>, the inequality reduces to the triangle inequality for absolute values, which is trivially true.</p></li>
<li><p>For <span class="math">\(p&gt;1\)</span>, we use Hölder's inequality, which for <span class="math">\(\frac{1}{p} + \frac{1}{q} = 1\)</span> (where <span class="math">\(p,q&gt;1\)</span>), states:</p></li>
</ul>
<div class="math">
\begin{equation*}
\sum_{i=1}^{n} |\xi _i \eta _i| \leq \left(\sum_{i=1}^{n} |\xi _i|^p\right)^{1/p} \left(\sum_{i=1}^{n} |\eta _i|^q\right)^{1/q}
\end{equation*}
</div>
<p>By applying Hölder's inequality, we rewrite the left side of Minkowski's inequality as follows:</p>
<div class="math">
\begin{equation*}
\sum_{i=1}^{n} |\xi _i + \eta _i|^p = \sum_{i=1}^{n} |\xi _i + \eta _i|^{p-1} |\xi _i + \eta _i|
\end{equation*}
</div>
<p>We then apply Hölder's inequality with <span class="math">\(|\xi _i + \eta _i|^{p-1}\)</span> and <span class="math">\(|\xi _i + \eta _i|\)</span> as the sequences, and by doing the same for <span class="math">\(|\eta _i|\)</span> instead of <span class="math">\(|\xi _i|\)</span>, and then summing the inequalities, we obtain:</p>
<div class="math">
\begin{equation*}
\left(\sum_{i=1}^{n} |\xi _i + \eta _i|^p\right) \leq \left(\sum_{i=1}^{n} |\xi _i + \eta _i|^p\right)^{\frac{p}{p-1}} \left(\left(\sum_{i=1}^{n} |\xi _i|^p\right)^{1/p} + \left(\sum_{i=1}^{n} |\eta _i|^p\right)^{1/p}\right)
\end{equation*}
</div>
<p>Raising both sides to the <span class="math">\(\frac{1}{p}\)</span> power completes the proof of Minkowski's inequality and establishes the triangle inequality for the <span class="math">\(p\)</span>-norm.</p>
<p>By verifying that each function satisfies all four norm properties, we show that <span class="math">\(||x||_1\)</span>, <span class="math">\(||x||_p\)</span>, and <span class="math">\(||x||_\infty\)</span> each define a norm on the vector space XX.</p>
<hr class="docutils" />
<p><strong>Problem 9.</strong> Verify that the space <span class="math">\(C[a, b]\)</span> with the norm given by</p>
<div class="math">
\begin{equation*}
\|x\| = \max_{t \in [a, b]} |x(t)|
\end{equation*}
</div>
<p>where <span class="math">\([a, b]\)</span> is the interval, defines a norm.</p>
<p><strong>Solution:</strong></p>
<p>To verify that the given formula defines a norm on the space <span class="math">\(C[a, b]\)</span>, we need to check that it satisfies the following properties for all functions <span class="math">\(x, y \in C[a, b]\)</span> and all scalars <span class="math">\(\lambda\)</span>:</p>
<ol class="arabic simple">
<li><p>Non-negativity: <span class="math">\(\|x\| \geq 0\)</span>, and <span class="math">\(\|x\| = 0\)</span> if and only if <span class="math">\(x(t) = 0\)</span> for all <span class="math">\(t \in [a, b]\)</span>.</p></li>
<li><p>Absolute scalability: <span class="math">\(\|\lambda x\| = |\lambda| \|x\|\)</span>.</p></li>
<li><p>Triangle inequality: <span class="math">\(\|x + y\| \leq \|x\| + \|y\|\)</span>.</p></li>
</ol>
<p><strong>Non-negativity</strong></p>
<p>For any <span class="math">\(x \in C[a, b]\)</span>, since <span class="math">\(x(t)\)</span> is a continuous function on a closed interval, it will attain a maximum absolute value which is non-negative. Thus, <span class="math">\(\|x\| = \max_{t \in [a, b]} |x(t)| \geq 0\)</span>. Also, <span class="math">\(\|x\| = 0\)</span> if and only if <span class="math">\(|x(t)| = 0\)</span> for all <span class="math">\(t\)</span>, which means <span class="math">\(x(t) = 0\)</span> for all <span class="math">\(t \in [a, b]\)</span>.</p>
<p><strong>Absolute scalability</strong></p>
<p>For any scalar <span class="math">\(\lambda\)</span> and any <span class="math">\(x \in C[a, b]\)</span>, we have:</p>
<div class="math">
\begin{equation*}
\|\lambda x\| = \max_{t \in [a, b]} |\lambda x(t)| = |\lambda| \max_{t \in [a, b]} |x(t)| = |\lambda| \|x\|
\end{equation*}
</div>
<p>This follows because the absolute value function is homogeneous, meaning <span class="math">\(|ab| = |a||b|\)</span> for all <span class="math">\(a, b\)</span>.</p>
<p><strong>Triangle inequality</strong></p>
<p>The triangle inequality states that for any <span class="math">\(x, y \in C[a, b]\)</span>, the norm of their sum is less than or equal to the sum of their norms:</p>
<div class="math">
\begin{equation*}
\|x + y\| = \max_{t \in [a, b]} |x(t) + y(t)| \leq \max_{t \in [a, b]} (|x(t)| + |y(t)|) \leq \max_{t \in [a, b]} |x(t)| + \max_{t \in [a, b]} |y(t)| = \|x\| + \|y\|
\end{equation*}
</div>
<p>The inequality <span class="math">\(|x(t) + y(t)| \leq |x(t)| + |y(t)|\)</span> follows from the triangle inequality for absolute values, and we use the fact that the maximum value of a sum is less than or equal to the sum of the maximum values.</p>
<p>Since the given norm satisfies all three properties, it is indeed a norm on the space <span class="math">\(C[a, b]\)</span>.</p>
<p><strong>Clarification of Non-negativity Property:</strong></p>
<p>For any function <span class="math">\(x\)</span> in <span class="math">\(C[a, b]\)</span>, the norm is defined as</p>
<div class="math">
\begin{equation*}
\|x\| = \max_{t \in [a, b]} |x(t)|
\end{equation*}
</div>
<p>Since <span class="math">\(x(t)\)</span> is a continuous function on the closed interval <span class="math">\([a, b]\)</span>, it has the following properties:</p>
<ol class="arabic simple">
<li><p><strong>Boundedness</strong>: A continuous function on a closed interval is bounded. That is, there exists a real number <span class="math">\(M\)</span> such that <span class="math">\(|x(t)| \leq M\)</span> for all <span class="math">\(t \in [a, b]\)</span>.</p></li>
<li><p><strong>Attainment of Bounds</strong>: By the extreme value theorem, a continuous function on a closed interval attains its maximum and minimum values at least once within that interval. Therefore, there exists some <span class="math">\(t_{\text{max}} \in [a, b]\)</span> where <span class="math">\(|x(t_{\text{max}})| = \max_{t \in [a, b]} |x(t)|\)</span>.</p></li>
</ol>
<p>With these properties, the non-negativity of the norm can be discussed in detail:</p>
<ul class="simple">
<li><p><strong>Non-negativity</strong>: The norm <span class="math">\(\|x\|\)</span> is always non-negative because absolute values are non-negative, and because <span class="math">\(x\)</span> is continuous, it achieves a maximum absolute value on <span class="math">\([a, b]\)</span>. This maximum is the value of the norm and cannot be negative.</p></li>
<li><p><strong>Zero Norm</strong>: The norm <span class="math">\(\|x\|\)</span> is zero if and only if the maximum absolute value that <span class="math">\(x(t)\)</span> achieves over the interval <span class="math">\([a, b]\)</span> is zero. If <span class="math">\(\|x\| = 0\)</span>, then <span class="math">\(\max_{t \in [a, b]} |x(t)| = 0\)</span>, implying that <span class="math">\(|x(t)| = 0\)</span> for all <span class="math">\(t \in [a, b]\)</span>. Since a real number's absolute value is zero if and only if the number itself is zero, it follows that <span class="math">\(x(t) = 0\)</span> for all <span class="math">\(t \in [a, b]\)</span>. Conversely, if <span class="math">\(x(t) = 0\)</span> for all <span class="math">\(t \in [a, b]\)</span>, then clearly <span class="math">\(\|x\| = 0\)</span>.</p></li>
</ul>
<p>These points confirm the non-negativity of the norm and the condition under which the norm of a function is zero.</p>
<p><strong>Why a Continuous Function on a Closed Interval is Bounded:</strong></p>
<p>A continuous function on a closed interval ([a, b]) is guaranteed to be bounded. This assertion is supported by the Boundedness Theorem, which is a direct consequence of the Extreme Value Theorem. The reasoning is as follows:</p>
<ul class="simple">
<li><p><strong>Closed Interval</strong>: A closed interval <span class="math">\([a, b]\)</span> includes its endpoints, making it a compact set in the real numbers. Compactness in real numbers implies that the set is both closed and bounded.</p></li>
<li><p><strong>Continuity</strong>: A function <span class="math">\(f\)</span> is continuous on <span class="math">\([a, b]\)</span> if, for every point <span class="math">\(c\)</span> in the interval and every <span class="math">\(\epsilon &gt; 0\)</span>, there exists a <span class="math">\(\delta &gt; 0\)</span> such that for all <span class="math">\(x\)</span> within <span class="math">\(\delta\)</span> of <span class="math">\(c\)</span>, the value of <span class="math">\(f(x)\)</span> is within <span class="math">\(\epsilon\)</span> of <span class="math">\(f(c)\)</span>. This means the function does not exhibit jumps, breaks, or infinite behavior within the interval.</p></li>
<li><p><strong>Extreme Value Theorem</strong>: Due to continuity and the closed nature of the interval, the Extreme Value Theorem ensures that a continuous function on a closed interval will attain both its maximum and minimum values within that interval. This theorem does not hold for open intervals or functions that are not continuous.</p></li>
</ul>
<p><strong>Intuitive Explanation</strong>:</p>
<p>If a continuous function were not bounded on a closed interval, it would suggest that the function could assume arbitrarily large or small values. However, continuity ensures a gradual change without sudden leaps. As the interval is closed, the function cannot 'escape' to infinity at the endpoints, because these points are part of the interval and the function must be defined and finite at them. If the function were unbounded, there would exist points where the function's values would become arbitrarily large, contradicting the very definition of continuity.</p>
<p>Thus, the interplay between the function's continuity (precluding abrupt changes or infinite values) and the interval's closed nature (disallowing endpoints from being unbounded) ensures that the function must be bounded.</p>
<hr class="docutils" />
<p><strong>Problem Statement</strong> Show that the closed unit ball <span class="math">\(\tilde{B}_1(0)\)</span> in a normed space <span class="math">\(X\)</span> is convex.</p>
<p><strong>Solution:</strong>
To prove that the closed unit ball <span class="math">\(\tilde{B}_1(0)\)</span> is convex, we need to demonstrate that for any two points <span class="math">\(x, y \in \tilde{B}_1(0)\)</span>, the line segment joining them is entirely contained within <span class="math">\(\tilde{B}_1(0)\)</span>. A line segment in a vector space can be represented as the set of all convex combinations of <span class="math">\(x\)</span> and <span class="math">\(y\)</span>, which is given by</p>
<div class="math">
\begin{equation*}
z = \alpha x + (1 - \alpha) y
\end{equation*}
</div>
<p>where <span class="math">\(0 \leq \alpha \leq 1\)</span>. The point <span class="math">\(z\)</span> is a point on the line segment between <span class="math">\(x\)</span> and <span class="math">\(y\)</span>, varying smoothly from one to the other as <span class="math">\(\alpha\)</span> goes from 0 to 1.</p>
<p>Now, we must show that <span class="math">\(z\)</span> also belongs to <span class="math">\(\tilde{B}_1(0)\)</span>, which means that <span class="math">\(\|z\| \leq 1\)</span>. Given that <span class="math">\(x, y \in \tilde{B}_1(0)\)</span>, we have <span class="math">\(\|x\| \leq 1\)</span> and <span class="math">\(\|y\| \leq 1\)</span>. The norm of <span class="math">\(z\)</span> is computed as follows:</p>
<div class="math">
\begin{equation*}
\|z\| = \|\alpha x + (1 - \alpha) y\| \leq \alpha \|x\| + (1 - \alpha) \|y\|
\end{equation*}
</div>
<p>Here we have used the triangle inequality and the property of absolute scalability of norms. Because <span class="math">\(\|x\| \leq 1\)</span> and <span class="math">\(\|y\| \leq 1\)</span>, it follows that:</p>
<div class="math">
\begin{equation*}
\alpha \|x\| + (1 - \alpha) \|y\| \leq \alpha \cdot 1 + (1 - \alpha) \cdot 1 = \alpha + 1 - \alpha = 1
\end{equation*}
</div>
<p>Hence, <span class="math">\(\|z\| \leq 1\)</span>, which implies that <span class="math">\(z\)</span> is in <span class="math">\(\tilde{B}_1(0)\)</span>. This confirms that <span class="math">\(\tilde{B}_1(0)\)</span> is convex, as every point <span class="math">\(z\)</span> formed as a convex combination of any two points <span class="math">\(x\)</span> and <span class="math">\(y\)</span> in <span class="math">\(\tilde{B}_1(0)\)</span> also lies within <span class="math">\(\tilde{B}_1(0)\)</span>.</p>
<p><strong>Explanation:</strong></p>
<p>The point <span class="math">\(z = \alpha x + (1 - \alpha) y\)</span> is crucial in the definition of a convex set because it represents any point on the line segment between two points <span class="math">\(x\)</span> and <span class="math">\(y\)</span> within a vector space <span class="math">\(X\)</span>. The scalar <span class="math">\(\alpha\)</span> ranges from 0 to 1 and determines the position of <span class="math">\(z\)</span> on the line segment:</p>
<ul class="simple">
<li><p>When <span class="math">\(\alpha = 0\)</span>, the expression becomes <span class="math">\(z = 0 \cdot x + (1 - 0) \cdot y = y\)</span>, placing <span class="math">\(z\)</span> at the point <span class="math">\(y\)</span>.</p></li>
<li><p>When <span class="math">\(\alpha = 1\)</span>, it simplifies to <span class="math">\(z = 1 \cdot x + (1 - 1) \cdot y = x\)</span>, positioning <span class="math">\(z\)</span> at the point <span class="math">\(x\)</span>.</p></li>
<li><p>For values of <span class="math">\(\alpha\)</span> between 0 and 1, <span class="math">\(z\)</span> lies within the line segment connecting <span class="math">\(x\)</span> and <span class="math">\(y\)</span>.</p></li>
</ul>
<p>A set is convex if, for every pair of points within the set, the entire line segment that connects them also lies within the set. The point <span class="math">\(z\)</span> symbolizes a general point on the line segment between <span class="math">\(x\)</span> and <span class="math">\(y\)</span>. Demonstrating that for all values of <span class="math">\(\alpha\)</span> in the closed interval [0, 1], <span class="math">\(z\)</span> remains within the set proves the set's convexity. This is the essence of why the expression <span class="math">\(z = \alpha x + (1 - \alpha) y\)</span> is used: it is a generic representation of any point on the line segment, and verifying that all such points are contained within the set for all <span class="math">\(\alpha\)</span> in [0, 1] affirms the convexity of the set.</p>
